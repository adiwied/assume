# SPDX-FileCopyrightText: ASSUME Developers
#
# SPDX-License-Identifier: AGPL-3.0-or-later

base:
  end_date: 2019-03-31 00:00
  learning_mode: true
  learning_config:
    continue_learning: False
    trained_policies_save_path: null
    max_bid_price: 100
    algorithm: matd3
    device: cpu
    learning_rate: 0.0003
    validation_episodes_interval: 10 # after how many episodes the validation starts and the policy is updated
    training_episodes: 100
    gradient_steps: 10
    matd3:
      actor_architecture: mlp
      train_freq: 24h # how often write_to_learning_role gets called
      episodes_collecting_initial_experience: 3
      batch_size: 64
      gamma: 0.99
      noise_sigma: 0.1
      noise_scale: 1
      noise_dt: 1
  markets_config:
    EOM:
      market_mechanism: pay_as_clear
      maximum_bid_price: 3000
      maximum_bid_volume: 100000
      minimum_bid_price: -500
      opening_duration: 1h
      opening_frequency: 1h
      operator: EOM_operator
      price_unit: EUR/MWh
      product_type: energy
      products:
      - count: 1
        duration: 1h
        first_delivery: 1h
      volume_unit: MWh
  save_frequency_hours: null
  start_date: 2019-03-01 00:00
  time_step: 1h

base_lstm:
  end_date: 2019-03-31 00:00
  learning_config:
    continue_learning: False
    trained_policies_save_path: null
    max_bid_price: 100
    algorithm: matd3
    device: cpu
    learning_rate: 0.0003
    validation_episodes_interval: 10 # after how many episodes the validation starts and the policy is updated
    training_episodes: 100
    gradient_steps: 10
    matd3:
      actor_architecture: lstm
      train_freq: 24h # how often write_to_learning_role gets called
      episodes_collecting_initial_experience: 3
      batch_size: 64
      gamma: 0.99
      noise_sigma: 0.1
      noise_scale: 1
      noise_dt: 1
  learning_mode: true
  markets_config:
    EOM:
      market_mechanism: pay_as_clear
      maximum_bid_price: 3000
      maximum_bid_volume: 100000
      minimum_bid_price: -500
      opening_duration: 1h
      opening_frequency: 1h
      operator: EOM_operator
      price_unit: EUR/MWh
      product_type: energy
      products:
      - count: 1
        duration: 1h
        first_delivery: 1h
      volume_unit: MWh
      maximum_bid_volume: 100000
      maximum_bid_price: 3000
      minimum_bid_price: -500
      price_unit: EUR/MWh
      market_mechanism: pay_as_clear


tiny_ppo:
  start_date: 2019-01-01 00:00
  end_date: 2019-01-05 00:00 
  time_step: 1h
  save_frequency_hours: null
  learning_mode: True
  learning_config:
    continue_learning: False
    trained_policies_save_path: null
    max_bid_price: 100
    algorithm: ppo
    device: cpu
    learning_rate: 0.0003
    validation_episodes_interval: 10 # after how many episodes the validation starts and the policy is updated
    training_episodes: 100
    gradient_steps: 10
    matd3:
      actor_architecture: mlp
      train_freq: 24h # how often write_to_learning_role gets called
      episodes_collecting_initial_experience: 3
      batch_size: 64
      gamma: 0.99
      noise_sigma: 0.1
      noise_scale: 1
      noise_dt: 1
    ppo: 
      actor_architecture: dist
      train_freq: 33h # how often write_to_learning_role gets called
      gamma: 0.99 # Discount factor for future rewards
      clip_ratio: 0.05  # Clipping parameter for policy updates
      vf_coef: 0.75  # Value function coefficient in the loss function
      entropy_coef: 0.005  # Entropy coefficient for exploration
      max_grad_norm: 0.3  # Gradient clipping value
      gae_lambda: 0.95  # GAE lambda for advantage estimation
      batch_size: 11  # Batch size for each update, if mini-batch approach is used (currently not implemented)
  markets_config:
    EOM:
      operator: EOM_operator
      product_type: energy
      products:
        - duration: 1h
          count: 1
          first_delivery: 1h
      opening_frequency: 1h
      opening_duration: 1h
      volume_unit: MWh
      maximum_bid_volume: 100000
      maximum_bid_price: 3000
      minimum_bid_price: -500
      price_unit: EUR/MWh
      market_mechanism: pay_as_clear


base_ppo:
  start_date: 2019-03-01 00:00
  end_date: 2019-03-31 00:00
  time_step: 1h
  save_frequency_hours: null
  learning_mode: True
  learning_config:
    continue_learning: False
    trained_policies_save_path: null
    max_bid_price: 100
    algorithm: ppo
    device: cpu
    learning_rate: 0.0003
    validation_episodes_interval: 10 # after how many episodes the validation starts and the policy is updated
    training_episodes: 100
    gradient_steps: 10
    matd3:
      actor_architecture: mlp
      train_freq: 24h # how often write_to_learning_role gets called
      episodes_collecting_initial_experience: 3
      batch_size: 64
      gamma: 0.99
      noise_sigma: 0.1
      noise_scale: 1
      noise_dt: 1
    ppo: 
      actor_architecture: dist
      train_freq: 33h # how often write_to_learning_role gets called
      gamma: 0.99 # Discount factor for future rewards
      clip_ratio: 0.05  # Clipping parameter for policy updates
      vf_coef: 0.75  # Value function coefficient in the loss function
      entropy_coef: 0.005  # Entropy coefficient for exploration
      max_grad_norm: 0.3  # Gradient clipping value
      gae_lambda: 0.95  # GAE lambda for advantage estimation
      batch_size: 11  # Batch size for each update, if mini-batch approach is used (currently not implemented)

  markets_config:
    EOM:
      operator: EOM_operator
      product_type: energy
      products:
        - duration: 1h
          count: 1
          first_delivery: 1h
      opening_frequency: 1h
      opening_duration: 1h
      volume_unit: MWh
      maximum_bid_volume: 100000
      maximum_bid_price: 3000
      minimum_bid_price: -500
      price_unit: EUR/MWh
      market_mechanism: pay_as_clear

base_lstm:
  start_date: 2019-03-01 00:00
  time_step: 1h
tiny:
  end_date: 2019-01-05 00:00
  learning_config:
    continue_learning: False
    trained_policies_save_path: null
    max_bid_price: 100
    algorithm: ppo
    device: cpu
    learning_rate: 0.0003
    validation_episodes_interval: 10 # after how many episodes the validation starts and the policy is updated
    training_episodes: 100
    gradient_steps: 10
    matd3:
      actor_architecture: mlp
      train_freq: 24h # how often write_to_learning_role gets called
      episodes_collecting_initial_experience: 3
      batch_size: 64
      gamma: 0.99
      noise_sigma: 0.1
      noise_scale: 1
      noise_dt: 1
  learning_mode: true
  markets_config:
    EOM:
      market_mechanism: pay_as_clear
      maximum_bid_price: 3000
      maximum_bid_volume: 100000
      minimum_bid_price: -500
      opening_duration: 1h
      opening_frequency: 1h
      operator: EOM_operator
      price_unit: EUR/MWh
      product_type: energy
      products:
      - count: 1
        duration: 1h
        first_delivery: 1h
      volume_unit: MWh
  save_frequency_hours: null
  start_date: 2019-01-01 00:00
  time_step: 1h
